{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Segy bin header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Header - заголовок размера 400 байт, который содержит некоторое числовое описание SEG-Y файла и данных, хранящихся в нем. Бинарный заголовок состоит из именованных полей и их значений, подробное описание всех полей можно прочитать в SEG Technical Standards Committee SEG-Y revision 2.0 Data Exchange format (https://seg.org/Portals/0/SEG/News%20and%20Resources/Technical%20Standards/seg_y_rev2_0-mar2017.pdf)\n",
    "\n",
    "Рассмотрим функционал библиотеки для работы с бинарным заголовком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seismo_reader as sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Описание класса "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бинарный заголовок представлен классом sr.segy_bin_header. Описание методов класса можно получить по команде help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class segy_bin_header in module seismo_reader.seismo_reader:\n",
      "\n",
      "class segy_bin_header(abstract_header)\n",
      " |  Method resolution order:\n",
      " |      segy_bin_header\n",
      " |      abstract_header\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      __init__(*args, **kwargs)\n",
      " |      Overloaded function.\n",
      " |      \n",
      " |      1. __init__(self: seismo_reader.seismo_reader.segy_bin_header) -> None\n",
      " |      \n",
      " |      2. __init__(self: seismo_reader.seismo_reader.segy_bin_header, fields_dict: Dict[str, Union[str, int, int, int, int, int, int, int, float, float, str]]) -> None\n",
      " |  \n",
      " |  raw_data(...)\n",
      " |      raw_data(self: seismo_reader.seismo_reader.segy_bin_header) -> List[int]\n",
      " |      \n",
      " |      Returns byte array in SEG-Y raw format\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from abstract_header:\n",
      " |  \n",
      " |  description(...)\n",
      " |      description(self: seismo_reader.seismo_reader.abstract_header) -> Dict[str, Dict[str, str]]\n",
      " |      \n",
      " |      Get description for header fields\n",
      " |  \n",
      " |  from_dict(...)\n",
      " |      from_dict(self: seismo_reader.seismo_reader.abstract_header, arg0: Dict[str, Union[str, int, int, int, int, int, int, int, float, float, str]]) -> None\n",
      " |      \n",
      " |      Set header from dict kind of { field name : value }\n",
      " |  \n",
      " |  get(...)\n",
      " |      get(self: seismo_reader.seismo_reader.abstract_header, field_name: str) -> Union[str, int, int, int, int, int, int, int, float, float, str]\n",
      " |      \n",
      " |      Returns pair (field name, value) by name\n",
      " |  \n",
      " |  set(...)\n",
      " |      set(self: seismo_reader.seismo_reader.abstract_header, field_name: str, value: Union[str, int, int, int, int, int, int, int, float, float, str]) -> None\n",
      " |      \n",
      " |      Set value for field\n",
      " |  \n",
      " |  to_dict(...)\n",
      " |      to_dict(self: seismo_reader.seismo_reader.abstract_header) -> Dict[str, Union[str, int, int, int, int, int, int, int, float, float, str]]\n",
      " |      \n",
      " |      Returns dict kind of { field name : value }\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sr.segy_bin_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из помощи, класс является некоторым хранилищем значений вида __{'имя поля заголовка': значение}__ и поддерживает преобразование в/из __dict__.\n",
    "\n",
    "Дополнительно представлены функции __get/set__, позволяющие манипулировать отдельными полями, что предпочтительнее в случае, когда необходимо обработать лишь небольшое число полей заголовка.\n",
    "\n",
    "Доступен как пустой конструктор, так и конструктор из словаря. Есть возможность получить \"сырые\" 400 байт заголовка при помощи метода __raw_data__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Чтение и просмотр бинарного заголовка из SEG-Y файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример чтения бинарного заголовка из SEG-Y файла, опробуем функционал класса и приведем полученную информацию в _Userfriendly_ вид."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = sr.reader_config()\n",
    "config.filename = '2D.segy'\n",
    "reader = sr.segy_reader(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получить бинарный заголовок из открытого SEG-Y файла можно методом segy_reader.bin_header() (см. ?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = reader.bin_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем бинарный заголовок в словарь и посмотрим на его содержимое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amplitude rec method': 0,\n",
       " 'Aux traces count': 0,\n",
       " 'Correlated traces': 0,\n",
       " 'Data format': 8,\n",
       " 'Endian': 0,\n",
       " 'Ensemble fold': 1,\n",
       " 'Extended aux traces count': 0,\n",
       " 'Extended ensemble fold': 0,\n",
       " 'Extended sample interval': 0.0,\n",
       " 'Extended sample interval orig': 0.0,\n",
       " 'Extended samples count': 0,\n",
       " 'Extended samples count orig': 0,\n",
       " 'Extended text headers count': 0,\n",
       " 'Extended traces count': 0,\n",
       " 'First trace offset': 0,\n",
       " 'Gain recovered': 0,\n",
       " 'Is same for file': 0,\n",
       " 'Is segy 2': 0,\n",
       " 'Job id': 1,\n",
       " 'Line num': 1,\n",
       " 'Max add trc headers count': 0,\n",
       " 'Measurement system': 1,\n",
       " 'Polarity code': 0,\n",
       " 'Reel num': 1,\n",
       " 'Sample interval': 2000.0,\n",
       " 'Sample interval orig': 0.0,\n",
       " 'Samples count': 1801,\n",
       " 'Samples count orig': 0,\n",
       " 'Signal polarity': 1,\n",
       " 'Sorting code': 4,\n",
       " 'Stream traces count': 0,\n",
       " 'Sweep chanel trcs count': 0,\n",
       " 'Sweep fr end': 0,\n",
       " 'Sweep fr start': 0,\n",
       " 'Sweep len': 0,\n",
       " 'Sweep trc taper len end': 0,\n",
       " 'Sweep trc taper len start': 0,\n",
       " 'Sweep type': 0,\n",
       " 'Taper type': 0,\n",
       " 'Time basis': 0,\n",
       " 'Traces count': 1,\n",
       " 'Vert sum code': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из содержимого, бинарный заголовок состоит из более чем сорока именованных полей.<br>\n",
    "Некоторые поля имеют нулевое значение, это скорее всего означает, что такие поля не играют роли в интерпретации содержимого файла.\n",
    "\n",
    "Наиболее важными полями являются:<br>\n",
    " >__Samples count__ - количество отсчетов в трассе,<br>\n",
    " >__Sample interval__ - временной (или глубинный) интервал между отсчетами в трассе<br>\n",
    " >__Data format__ - формат данных в трассе\n",
    " >__Endian__ - порядок байт при записи чисел в файле<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение по полю можно получить не только из словаря, но и методом get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# По словарю\n",
    "bh.to_dict()['Data format']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Методом get\n",
    "bh.get('Data format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имя поля можно вводить и в другом формате: без заглавной буквы и с '_' в качестве разделителя слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh.get('data_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же класс предоставляет краткое описание каждого поля, которое можно получить с помощью метода __description__.<br>\n",
    "Помимо самого описания предоставляются диапазоны байт для сопостовления с документацией.\n",
    "\n",
    "Вывод всего словаря description довольно сложен для понимания, поэтому рассмотрим лишь описание поля __Data format__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bytes': '3225-3226', 'Description': \"Data sample format code:\\n\\t1 - 4-byte IBM float\\n\\t2 - 4-byte, two's complement integer\\n\\t3 - 2-byte, two's complement integer\\n\\t4 - 4-byte fixed-point with gain (obsolete)\\n\\t5 - 4-byte IEEE float\\n\\t6 - 8-byte IEEE float\\n\\t7 - 3-byte two's complement integer\\n\\t8 - 1-byte, two's complement integer\\n\\t9 - 8-byte, two's complement integer\\n\\t10 - 4-byte, unsigned integer\\n\\t11 - 2-byte, unsigned integer\\n\\t12 - 8-byte, unsigned integer\\n\\t15 - 3-byte, unsigned integer\\n\\t16 - 1-byte, unsigned integer\"}\n"
     ]
    }
   ],
   "source": [
    "print(bh.description()['Data format'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно выведем диапазон байт и описание для поля __Data format__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3225-3226\n"
     ]
    }
   ],
   "source": [
    "# Диапазон байт\n",
    "print(bh.description()['Data format']['Bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sample format code:\n",
      "\t1 - 4-byte IBM float\n",
      "\t2 - 4-byte, two's complement integer\n",
      "\t3 - 2-byte, two's complement integer\n",
      "\t4 - 4-byte fixed-point with gain (obsolete)\n",
      "\t5 - 4-byte IEEE float\n",
      "\t6 - 8-byte IEEE float\n",
      "\t7 - 3-byte two's complement integer\n",
      "\t8 - 1-byte, two's complement integer\n",
      "\t9 - 8-byte, two's complement integer\n",
      "\t10 - 4-byte, unsigned integer\n",
      "\t11 - 2-byte, unsigned integer\n",
      "\t12 - 8-byte, unsigned integer\n",
      "\t15 - 3-byte, unsigned integer\n",
      "\t16 - 1-byte, unsigned integer\n"
     ]
    }
   ],
   "source": [
    "# Само описание\n",
    "print(bh.description()['Data format']['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в представленном файле отсчеты трасс хранятся в формате __1-byte, two's complement integer__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем полученную информацию в более красивый вид для вывода пользователю-интерпретатору.\n",
    "\n",
    "Для этого сделаем следующее:<br>\n",
    ">1. Разделим полученный словарь полей и значений бинарного заголовка на 2 части: ненулевую и нулевую.\n",
    ">2. Отсортируем отдельно обе части по диапазону байт (для более удобного сопоставления с документацией).\n",
    ">3. Добавим к каждому поля описание и выведем все это на экран.\n",
    "\n",
    "Работа со словарями в таких операциях довольно сложна, на помощь приходит мощный инструмент pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним словарь в переменную d\n",
    "d = bh.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним отдельно 2 DataFrame'а, один со значениями полей, второй с описанием\n",
    "df_values = pd.DataFrame({'Value' : list(d.values())}, index=list(d.keys()))\n",
    "df_descr = pd.DataFrame.from_dict(bh.description()).T\n",
    "\n",
    "# Сольем в единый DataFrame\n",
    "df = pd.concat([df_values, df_descr], axis=1)\n",
    "\n",
    "# Отсортируем ненулевую и нулевую часть по диапазонам байт\n",
    "df = pd.concat([\n",
    "    df[df['Value'] > 0].sort_values(by=['Bytes'], ascending=True),\n",
    "    df[df['Value'] <= 0].sort_values(by=['Bytes'], ascending=True)],\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Bytes</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job id</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3201-3204</td>\n",
       "      <td>Job identification number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line num</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3205-3208</td>\n",
       "      <td>Line number. For 3D data, this will contain th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reel num</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3209-3212</td>\n",
       "      <td>Reel number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traces count</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3213-3214</td>\n",
       "      <td>Number of data traces per ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample interval</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>3217-3218</td>\n",
       "      <td>Sample interval (us / Hz / m / ft)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samples count</th>\n",
       "      <td>1801.0</td>\n",
       "      <td>3221-3222</td>\n",
       "      <td>Number of samples per data trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data format</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3225-3226</td>\n",
       "      <td>Data sample format code:\\n\\t1 - 4-byte IBM flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble fold</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3227-3228</td>\n",
       "      <td>The expected number of data traces per trace e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sorting code</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3229-3230</td>\n",
       "      <td>Trace sorting code:\\n\\t-1 - Other\\n\\t0 - Unkno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vert sum code</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3231-3232</td>\n",
       "      <td>Vertical sum code:\\n\\t1 - No sum\\n\\t2 - two su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Measurement system</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3255-3256</td>\n",
       "      <td>Measurement system (see Segy documentation):\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Signal polarity</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3257-3258</td>\n",
       "      <td>Impulse signal polarity:\\n\\t1 - Increase in pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Endian</th>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>Byte ordering to expect for this SEG-Y file:\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aux traces count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3215-3216</td>\n",
       "      <td>Number of auxiliary traces per ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample interval orig</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3219-3220</td>\n",
       "      <td>Sample interval of original field recording (u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samples count orig</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3223-3224</td>\n",
       "      <td>Number of samples per data trace for original ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep fr start</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3233-3234</td>\n",
       "      <td>Sweep frequency at start (Hz)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep fr end</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3235-3236</td>\n",
       "      <td>Sweep frequency at end (Hz)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep len</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3237-3238</td>\n",
       "      <td>Sweep length (ms)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep type</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3239-3240</td>\n",
       "      <td>Sweep type code:\\n\\t1 - Linear\\n\\t2 - Paraboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep chanel trcs count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3241-3242</td>\n",
       "      <td>Trace number of sweep channel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep trc taper len start</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3243-3244</td>\n",
       "      <td>Sweep trace taper length in milliseconds at st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweep trc taper len end</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3245-3246</td>\n",
       "      <td>Sweep trace taper length in milliseconds at en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taper type</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3247-3248</td>\n",
       "      <td>Taper type:\\n\\t1 - Linear\\n\\t2 - Cosine square...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Correlated traces</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3249-3250</td>\n",
       "      <td>Correlated data traces:\\n\\t 1 - No\\n\\t2 = Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gain recovered</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3251-3252</td>\n",
       "      <td>Binary gain recovered:\\n\\t1 - Yes\\n\\t2 = No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amplitude rec method</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3253-3254</td>\n",
       "      <td>Amplitude recovery method:\\n\\t1 - None\\n\\t2 - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polarity code</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3259-3260</td>\n",
       "      <td>Vibratory polarity code (seismic signal lags p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended traces count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3261-3264</td>\n",
       "      <td>Extended number of data traces per ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended aux traces count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3265-3268</td>\n",
       "      <td>Extended number of auxiliary traces per ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended samples count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3269-3272</td>\n",
       "      <td>Extended number of samples per data trace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended sample interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3273-3280</td>\n",
       "      <td>Extended sample interval, IEEE double precisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended sample interval orig</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3281-3288</td>\n",
       "      <td>Extended sample interval of original field rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended samples count orig</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3289-3292</td>\n",
       "      <td>Extended number of samples per data trace in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended ensemble fold</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3293-3296</td>\n",
       "      <td>Extended ensemble fold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is segy 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3501-3501</td>\n",
       "      <td>Major SEG-Y Format Revision Number. A value of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is same for file</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3503-3504</td>\n",
       "      <td>A value of one indicates that all traces in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extended text headers count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3505-3506</td>\n",
       "      <td>Number of 3200-byte, Extended Textual File Header</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max add trc headers count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3507-3510</td>\n",
       "      <td>Maximum number of additional 240 byte trace he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time basis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3511-3512</td>\n",
       "      <td>Time basis code:\\n\\t1 - Local\\n\\t2 - GMT\\n\\t3 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stream traces count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3513-3520</td>\n",
       "      <td>Number of traces in this file or stream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First trace offset</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3521-3528</td>\n",
       "      <td>Byte offset of first trace relative to start o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Value      Bytes  \\\n",
       "Job id                            1.0  3201-3204   \n",
       "Line num                          1.0  3205-3208   \n",
       "Reel num                          1.0  3209-3212   \n",
       "Traces count                      1.0  3213-3214   \n",
       "Sample interval                2000.0  3217-3218   \n",
       "Samples count                  1801.0  3221-3222   \n",
       "Data format                       8.0  3225-3226   \n",
       "Ensemble fold                     1.0  3227-3228   \n",
       "Sorting code                      4.0  3229-3230   \n",
       "Vert sum code                     1.0  3231-3232   \n",
       "Measurement system                1.0  3255-3256   \n",
       "Signal polarity                   1.0  3257-3258   \n",
       "Endian                            0.0              \n",
       "Aux traces count                  0.0  3215-3216   \n",
       "Sample interval orig              0.0  3219-3220   \n",
       "Samples count orig                0.0  3223-3224   \n",
       "Sweep fr start                    0.0  3233-3234   \n",
       "Sweep fr end                      0.0  3235-3236   \n",
       "Sweep len                         0.0  3237-3238   \n",
       "Sweep type                        0.0  3239-3240   \n",
       "Sweep chanel trcs count           0.0  3241-3242   \n",
       "Sweep trc taper len start         0.0  3243-3244   \n",
       "Sweep trc taper len end           0.0  3245-3246   \n",
       "Taper type                        0.0  3247-3248   \n",
       "Correlated traces                 0.0  3249-3250   \n",
       "Gain recovered                    0.0  3251-3252   \n",
       "Amplitude rec method              0.0  3253-3254   \n",
       "Polarity code                     0.0  3259-3260   \n",
       "Extended traces count             0.0  3261-3264   \n",
       "Extended aux traces count         0.0  3265-3268   \n",
       "Extended samples count            0.0  3269-3272   \n",
       "Extended sample interval          0.0  3273-3280   \n",
       "Extended sample interval orig     0.0  3281-3288   \n",
       "Extended samples count orig       0.0  3289-3292   \n",
       "Extended ensemble fold            0.0  3293-3296   \n",
       "Is segy 2                         0.0  3501-3501   \n",
       "Is same for file                  0.0  3503-3504   \n",
       "Extended text headers count       0.0  3505-3506   \n",
       "Max add trc headers count         0.0  3507-3510   \n",
       "Time basis                        0.0  3511-3512   \n",
       "Stream traces count               0.0  3513-3520   \n",
       "First trace offset                0.0  3521-3528   \n",
       "\n",
       "                                                                     Description  \n",
       "Job id                                                 Job identification number  \n",
       "Line num                       Line number. For 3D data, this will contain th...  \n",
       "Reel num                                                             Reel number  \n",
       "Traces count                                  Number of data traces per ensemble  \n",
       "Sample interval                               Sample interval (us / Hz / m / ft)  \n",
       "Samples count                                   Number of samples per data trace  \n",
       "Data format                    Data sample format code:\\n\\t1 - 4-byte IBM flo...  \n",
       "Ensemble fold                  The expected number of data traces per trace e...  \n",
       "Sorting code                   Trace sorting code:\\n\\t-1 - Other\\n\\t0 - Unkno...  \n",
       "Vert sum code                  Vertical sum code:\\n\\t1 - No sum\\n\\t2 - two su...  \n",
       "Measurement system             Measurement system (see Segy documentation):\\n...  \n",
       "Signal polarity                Impulse signal polarity:\\n\\t1 - Increase in pr...  \n",
       "Endian                         Byte ordering to expect for this SEG-Y file:\\n...  \n",
       "Aux traces count                         Number of auxiliary traces per ensemble  \n",
       "Sample interval orig           Sample interval of original field recording (u...  \n",
       "Samples count orig             Number of samples per data trace for original ...  \n",
       "Sweep fr start                                     Sweep frequency at start (Hz)  \n",
       "Sweep fr end                                         Sweep frequency at end (Hz)  \n",
       "Sweep len                                                      Sweep length (ms)  \n",
       "Sweep type                     Sweep type code:\\n\\t1 - Linear\\n\\t2 - Paraboli...  \n",
       "Sweep chanel trcs count                            Trace number of sweep channel  \n",
       "Sweep trc taper len start      Sweep trace taper length in milliseconds at st...  \n",
       "Sweep trc taper len end        Sweep trace taper length in milliseconds at en...  \n",
       "Taper type                     Taper type:\\n\\t1 - Linear\\n\\t2 - Cosine square...  \n",
       "Correlated traces                  Correlated data traces:\\n\\t 1 - No\\n\\t2 = Yes  \n",
       "Gain recovered                       Binary gain recovered:\\n\\t1 - Yes\\n\\t2 = No  \n",
       "Amplitude rec method           Amplitude recovery method:\\n\\t1 - None\\n\\t2 - ...  \n",
       "Polarity code                  Vibratory polarity code (seismic signal lags p...  \n",
       "Extended traces count                Extended number of data traces per ensemble  \n",
       "Extended aux traces count       Extended number of auxiliary traces per ensemble  \n",
       "Extended samples count                 Extended number of samples per data trace  \n",
       "Extended sample interval       Extended sample interval, IEEE double precisio...  \n",
       "Extended sample interval orig  Extended sample interval of original field rec...  \n",
       "Extended samples count orig    Extended number of samples per data trace in o...  \n",
       "Extended ensemble fold                                    Extended ensemble fold  \n",
       "Is segy 2                      Major SEG-Y Format Revision Number. A value of...  \n",
       "Is same for file               A value of one indicates that all traces in th...  \n",
       "Extended text headers count    Number of 3200-byte, Extended Textual File Header  \n",
       "Max add trc headers count      Maximum number of additional 240 byte trace he...  \n",
       "Time basis                     Time basis code:\\n\\t1 - Local\\n\\t2 - GMT\\n\\t3 ...  \n",
       "Stream traces count                      Number of traces in this file or stream  \n",
       "First trace offset             Byte offset of first trace relative to start o...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таком виде уже не стыдно показывать заголовок профессиональному интерпретатору.\n",
    "\n",
    "Однако, использовать pandas.DataFrame для хранения заголовка не рекомендуется. DataFrame хранит значения полей в едином типе (np.float), это может привести к дальнейшей потери данных, да и сам объект класса segy_bin_header не позволит устанавливать некоторые целочисленные поля при помощи числа с плавающей точкой.\n",
    "\n",
    "Рекомендуется манипулировать заголовком через pandas, но сохранять заголовок через сереализацию класса segy_bin_header, либо как словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка ошибок класса segy_bin_header осуществляется посредством исключений.\n",
    "\n",
    "Попытаемся получить несуществующее поле заголовка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "segy_bin_header.cpp:214: invalid field name",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1162083320ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'aaa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: segy_bin_header.cpp:214: invalid field name"
     ]
    }
   ],
   "source": [
    "bh.get('aaa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем исключение __ValueError__ с описанием _invalid field name_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же можно посмотреть (или манипулировать) с \"сырым\" заголовком через метод __raw_data__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   1,   0,   0,   0,   1,   0,   0,   0,   1,   0,\n",
       "         1,   0,   0,   7, -48,   0,   0,   7,   9,   0,   0,   0,   8,\n",
       "         0,   1,   0,   4,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   1,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbh = np.array(bh.raw_data(), dtype=np.int8) #int8 == byte\n",
    "\n",
    "rbh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер такого массива, как и ожидалось, 400 байт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Изменение бинарного заголовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для изменения содержимого бинарного заголовка предоставляются методы __set/from_dict__ и конструктор __init__(self, dict). \n",
    "\n",
    "Изменять бинарный заголовок, сопряженный со своим файлом, запрещено, так как настройки чтения файла (такие как data_format, endian) можно менять через класс segy_reader, а остальные поля в заголовке предоставляются для ознакомления с файлом.\n",
    "\n",
    "Действительно, попробовав изменить полученный из файла заголовок, получаем исключение (object is read only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "segy_bin_header.cpp:219: object is read only",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7179da3abd1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Через словарь:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: segy_bin_header.cpp:219: object is read only"
     ]
    }
   ],
   "source": [
    "# Через словарь:\n",
    "bh.from_dict(bh.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "segy_bin_header.cpp:219: object is read only",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f6b530cda4f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Через метод set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data format'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: segy_bin_header.cpp:219: object is read only"
     ]
    }
   ],
   "source": [
    "# Через метод set\n",
    "bh.set('Data format', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в бинарном заголовке есть ошибка, либо необходимо задать свои значения каки-либо полей, необходимо создать новый бинарный заголовок и далее работать с ним.\n",
    "\n",
    "Рассмотрим пример создания нового бинарного заголовка на основе bh с изменением некоторых полей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пустой бинарный заголовок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_new = sr.segy_bin_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем его поля в виде словаря, убедимся, что он пустой. Так рассмотрим \"сырое\" представление:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(bh_new.to_dict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(bh_new.raw_data(), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что у пустого бинарного заголовка \"сырое\" представление ненулевое. На позиции 92 (байты 92-93) стоят какие-то числа. Эти числа показывают, в каком порядке байт (endian) будет записан файл (вероятнее всего, сейчас там записан маркер для порядка big-endian). Даже при пустом заголовке класс segy_bin_header оставляет эту информацию. Все остальные байты нулевые."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним его поля, используя существующий заголовок bh и выведем новый заголовок в виде словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_new.from_dict(bh.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Amplitude rec method': 0,\n",
       " 'Aux traces count': 0,\n",
       " 'Correlated traces': 0,\n",
       " 'Data format': 8,\n",
       " 'Endian': 0,\n",
       " 'Ensemble fold': 1,\n",
       " 'Extended aux traces count': 0,\n",
       " 'Extended ensemble fold': 0,\n",
       " 'Extended sample interval': 0.0,\n",
       " 'Extended sample interval orig': 0.0,\n",
       " 'Extended samples count': 0,\n",
       " 'Extended samples count orig': 0,\n",
       " 'Extended text headers count': 0,\n",
       " 'Extended traces count': 0,\n",
       " 'First trace offset': 0,\n",
       " 'Gain recovered': 0,\n",
       " 'Is same for file': 0,\n",
       " 'Is segy 2': 0,\n",
       " 'Job id': 1,\n",
       " 'Line num': 1,\n",
       " 'Max add trc headers count': 0,\n",
       " 'Measurement system': 1,\n",
       " 'Polarity code': 0,\n",
       " 'Reel num': 1,\n",
       " 'Sample interval': 2000.0,\n",
       " 'Sample interval orig': 0.0,\n",
       " 'Samples count': 1801,\n",
       " 'Samples count orig': 0,\n",
       " 'Signal polarity': 1,\n",
       " 'Sorting code': 4,\n",
       " 'Stream traces count': 0,\n",
       " 'Sweep chanel trcs count': 0,\n",
       " 'Sweep fr end': 0,\n",
       " 'Sweep fr start': 0,\n",
       " 'Sweep len': 0,\n",
       " 'Sweep trc taper len end': 0,\n",
       " 'Sweep trc taper len start': 0,\n",
       " 'Sweep type': 0,\n",
       " 'Taper type': 0,\n",
       " 'Time basis': 0,\n",
       " 'Traces count': 1,\n",
       " 'Vert sum code': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_new.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуально словари старого и нового заголовка идентичны. Проверка на равенство так же проходит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh_new.to_dict() == bh.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, после обработки, мы изменили количество отсчетов в трассах, интервал отсчетов (применили какую-либо интерполяцию). Запишем новые значения этих полей в заголовок.\n",
    "\n",
    "Это можно сделать как через словарь, так и через метод __set__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "2600.0\n"
     ]
    }
   ],
   "source": [
    "# Через словарь:\n",
    "d = bh_new.to_dict()\n",
    "d.update({'Samples count': 500, 'Sample interval' : 2600})\n",
    "\n",
    "bh_new.from_dict(d)\n",
    "\n",
    "# Проверим изменения полей\n",
    "print(bh_new.to_dict()['Samples count'])\n",
    "print(bh_new.to_dict()['Sample interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000.0\n"
     ]
    }
   ],
   "source": [
    "# Через метод set:\n",
    "bh_new.set('Samples count', 1000)\n",
    "bh_new.set('Sample interval', 2000)\n",
    "\n",
    "# Проверим изменения полей\n",
    "print(bh_new.to_dict()['Samples count'])\n",
    "print(bh_new.to_dict()['Sample interval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые поля требуют только целочисленного значения. Так, например, попробовав изменить поле Data format в формате цисла с плавающей запятой, получаем исключение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "data_types.h:69: Mixing inappropriate types (float with enum segy_data_format)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3a8e9d1455aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbh_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data format'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: data_types.h:69: Mixing inappropriate types (float with enum segy_data_format)"
     ]
    }
   ],
   "source": [
    "bh_new.set('Data format', 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, некоторые поля класса segy_bin_header не просто целочисленные, а имеют тип enum. Установить их можно через целочисленное значение, или передав enum напрямую (рекомендуется второй вариант):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Целое число - OK\n",
    "bh_new.set('Data format', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum число - OK\n",
    "bh_new.set('Data format', sr.seismic_data_type.FLOAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Замечания "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменять поля __Data format__ и __Endian__ при записи SEG-Y файла не имеет смысла, эти поля будут автоматически перезаписаны исходя из конфигурации объекста segy_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
